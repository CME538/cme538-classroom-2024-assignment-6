{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CME538 - Introduction to Data Science\n",
    "## Lecture 6.2 - Gradient Descent I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 3rd party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import matplotlib.pylab as plt\n",
    "from ipywidgets import interact, fixed, IntSlider\n",
    "\n",
    "# Configure Notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"notebook\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tips Data\n",
    "Let's import out tips dataset from `Seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips = tips.iloc[0:-1]\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column representing the tip percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips['tip_pct'] = tips['tip'] / tips['total_bill'] * 100\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(tips['tip_pct'])\n",
    "ax.set_xlabel('Tip Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(theta, y_vals):\n",
    "    return np.mean((y_vals - theta) ** 2)\n",
    "\n",
    "def grad_mse(theta, y_vals):\n",
    "    return -2 * np.mean(y_vals - theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(loss_fn, grad_loss_fn, dataset, alpha=0.2, progress=True):\n",
    "    \"\"\"\n",
    "    Uses gradient descent to minimize loss_fn. \n",
    "    Returns the minimizing value of theta once \n",
    "    theta changes less than 0.001 between iterations.\n",
    "    \"\"\"\n",
    "    # Set starting theta\n",
    "    theta = 0\n",
    "    \n",
    "    # Set starting epoch\n",
    "    epoch = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(theta, dataset)\n",
    "        \n",
    "        if progress:\n",
    "            print('epoch: {} | theta: {} | loss: {}'.format(epoch, \n",
    "                                                            theta, \n",
    "                                                            loss))\n",
    "        \n",
    "        # Compute gradient\n",
    "        gradient = grad_loss_fn(theta, dataset)\n",
    "        \n",
    "        # Get new theta\n",
    "        new_theta = theta - alpha * gradient\n",
    "        \n",
    "        # Check for convergence\n",
    "        if abs(new_theta - theta) < 0.001:\n",
    "            return new_theta\n",
    "        \n",
    "        # Update theta\n",
    "        theta = new_theta\n",
    "        \n",
    "        # Update epoch\n",
    "        epoch += 1\n",
    "        \n",
    "    else:\n",
    "        return theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "theta = minimize(loss_fn=mse, \n",
    "                 grad_loss_fn=grad_mse, \n",
    "                 dataset=tips['tip_pct'].values, \n",
    "                 alpha=0.2, progress=True)\n",
    "\n",
    "print('\\nMinimizing theta: {}'.format(theta))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "theta = minimize(loss_fn=mse, \n",
    "                 grad_loss_fn=grad_mse, \n",
    "                 dataset=tips['tip_pct'].values, \n",
    "                 alpha=0.9, progress=True)\n",
    "\n",
    "print('\\nMinimizing theta: {}'.format(theta))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_plot_constant_model(epochs, loss_fn, grad_loss_fn, dataset, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Uses gradient descent to minimize loss_fn. Returns the minimizing value of\n",
    "    theta once theta changes less than 0.001 between iterations.\n",
    "    \"\"\"\n",
    "    # Set starting theta\n",
    "    theta = 90\n",
    "    \n",
    "    # Set starting epoch\n",
    "    epochs = np.arange(epochs)\n",
    "    epochs_conv = []\n",
    "    \n",
    "    # Set loss array\n",
    "    losses = []\n",
    "    losses_conv = []\n",
    "    \n",
    "    # Set theta array\n",
    "    thetas = []\n",
    "    \n",
    "    # Setup figure\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    ax1 = plt.subplot2grid((1, 2), (0, 0))\n",
    "    ax2 = plt.subplot2grid((1, 2), (0, 1))\n",
    "    \n",
    "    # Plot loss \n",
    "    sns.rugplot(tips['tip_pct'].values, height=0.1, ax=ax1)\n",
    "    ax1.plot(np.arange(-100, 120, 0.01), [loss_fn(val, dataset) for val in np.arange(-100, 120, 0.01)], '-')\n",
    "    ax1.set_xlabel('$\\\\theta$', fontsize=18)\n",
    "    ax1.set_ylabel('Loss', fontsize=18)\n",
    "    ax1.set_xlim([-60, 102])\n",
    "    ax1.set_ylim([-1000, 8000])\n",
    "    ax1.xaxis.set_tick_params(labelsize=14)\n",
    "    ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        # Update losses\n",
    "        losses.append(loss_fn(theta, dataset))\n",
    "        \n",
    "        # Update thetas\n",
    "        thetas.append(theta)\n",
    "        \n",
    "        # Compute gradient\n",
    "        gradient = grad_loss_fn(theta, dataset)\n",
    "        \n",
    "        # Get new theta\n",
    "        new_theta = theta - alpha * gradient\n",
    "        \n",
    "        if abs(new_theta - theta) < 0.001:\n",
    "            epochs_conv.append(epoch)\n",
    "            losses_conv.append(loss_fn(theta, dataset))\n",
    "          \n",
    "        # Update theta\n",
    "        theta = new_theta\n",
    "  \n",
    "    # Check for convergence\n",
    "    ax2.plot(epochs, losses, '-o', markeredgecolor='k', ms=10)\n",
    "    ax2.plot(epochs_conv, losses_conv, '-o', markeredgecolor='k', ms=10)\n",
    "    ax2.set_xlim([-0.5, 50])\n",
    "    ax2.set_ylim([-200, 8000])\n",
    "    ax2.set_xlabel('Epoch', fontsize=18)\n",
    "    ax2.set_ylabel('Loss', fontsize=18)\n",
    "    ax2.xaxis.set_tick_params(labelsize=14)\n",
    "    ax2.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "    ax1.set_title('$\\\\theta$ = {}'.format(np.round(theta, 2), fontsize=18))\n",
    "    ax1.plot(thetas, losses, '-o', markeredgecolor='k', ms=10)\n",
    "    \n",
    "    xs = np.arange(thetas[-1] - 30, thetas[-1] + 30, 0.05)\n",
    "    ys = losses[-1] + gradient * (xs - thetas[-1])\n",
    "    ax1.plot(xs, ys, zorder=0, linestyle='--', lw=2)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 1.01\n",
    "\n",
    "# Launch widget\n",
    "interact(minimize_plot_constant_model,\n",
    "         epochs=IntSlider(value=1, min=1, max=100, step=1),\n",
    "         loss_fn=fixed(mse),\n",
    "         grad_loss_fn=fixed(grad_mse),\n",
    "         dataset=fixed(tips['tip_pct'].values),\n",
    "         alpha=fixed(alpha));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Gradient  Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.scatterplot(x = tips['total_bill'], y = tips['tip'])\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=14)\n",
    "ax.set_xlabel('Total Bill', fontsize=18)\n",
    "ax.set_ylabel('Tip', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(theta, x, y_obs):\n",
    "    y_hat = theta * x\n",
    "    return np.mean((y_hat - y_obs) ** 2)\n",
    "\n",
    "def grad_mse(theta, x, y_obs):\n",
    "    y_hat = theta * x\n",
    "    return np.mean(2 * (y_hat - y_obs) * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_plot_1d_model(epochs, loss_fn, grad_loss_fn, x, y_obs, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Uses gradient descent to minimize loss_fn. Returns the minimizing value of\n",
    "    theta once theta changes less than 0.001 between iterations.\n",
    "    \"\"\"\n",
    "    # Set starting theta\n",
    "    theta = 90\n",
    "    \n",
    "    # Set starting epoch\n",
    "    epochs = np.arange(epochs)\n",
    "    epochs_conv = []\n",
    "    \n",
    "    # Set loss array\n",
    "    losses = []\n",
    "    losses_conv = []\n",
    "    \n",
    "    # Set theta array\n",
    "    thetas = []\n",
    "    \n",
    "    # Setup figure\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
    "    \n",
    "    # Plot total_bill vs tip\n",
    "    sns.scatterplot(x = x, y = y_obs, ax=ax1)\n",
    "    ax1.xaxis.set_tick_params(labelsize=14)\n",
    "    ax1.yaxis.set_tick_params(labelsize=14)\n",
    "    ax1.set_xlabel('Total Bill', fontsize=18)\n",
    "    ax1.set_ylabel('Tip', fontsize=18)\n",
    "    ax1.set_xlim([0, 60])\n",
    "    ax1.set_ylim([0, 12])\n",
    "    \n",
    "    # Plot loss \n",
    "    ax2.plot(np.arange(-100, 120, 0.01), [loss_fn(val, x, y_obs) for val in np.arange(-100, 120, 0.01)], '-')\n",
    "    ax2.set_xlabel('$\\\\theta$', fontsize=18)\n",
    "    ax2.set_ylabel('Loss', fontsize=18)\n",
    "    #ax2.set_xlim([-60, 102])\n",
    "    #ax2.set_ylim([-1000, 8000])\n",
    "    ax2.xaxis.set_tick_params(labelsize=14)\n",
    "    ax2.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        # Update losses\n",
    "        losses.append(loss_fn(theta, x, y_obs))\n",
    "        \n",
    "        # Update thetas\n",
    "        thetas.append(theta)\n",
    "        \n",
    "        # Compute gradient\n",
    "        gradient = grad_loss_fn(theta, x, y_obs)\n",
    "        \n",
    "        # Get new theta\n",
    "        new_theta = theta - alpha * gradient\n",
    "        \n",
    "        if abs(new_theta - theta) < 0.001:\n",
    "            epochs_conv.append(epoch)\n",
    "            losses_conv.append(loss_fn(theta, x, y_obs))\n",
    "          \n",
    "        # Update theta\n",
    "        theta = new_theta\n",
    "  \n",
    "    # Check for convergence\n",
    "    ax3.plot(epochs, losses, '-o', markeredgecolor='k', ms=10)\n",
    "    ax3.plot(epochs_conv, losses_conv, '-o', markeredgecolor='k', ms=10)\n",
    "    ax3.set_xlim([-0.5, 20])\n",
    "    #ax3.set_ylim([-200, 8000])\n",
    "    ax3.set_xlabel('Epoch', fontsize=18)\n",
    "    ax3.set_ylabel('Loss', fontsize=18)\n",
    "    ax3.xaxis.set_tick_params(labelsize=14)\n",
    "    ax3.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "    ax2.plot(thetas, losses, '-o', markeredgecolor='k', ms=10)\n",
    "    \n",
    "    xs = np.arange(thetas[-1] - 30, thetas[-1] + 30, 0.05)\n",
    "    ys = losses[-1] + gradient * (xs - thetas[-1])\n",
    "    ax2.plot(xs, ys, zorder=0, linestyle='--', lw=2)\n",
    "    \n",
    "    ax1.plot(x, x*theta, linestyle='-', lw=3, color='#fc4f30')\n",
    "    if len(losses_conv) > 0:\n",
    "        ax1.vlines(x, ymin=y_obs, ymax=x*theta, linestyle='dashed', color='r',alpha=0.3, zorder=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "\n",
    "# Launch widget\n",
    "interact(minimize_plot_1d_model,\n",
    "         epochs=IntSlider(value=1, min=1, max=20, step=1),\n",
    "         loss_fn=fixed(mse),\n",
    "         grad_loss_fn=fixed(grad_mse),\n",
    "         x=fixed(tips['total_bill'].values),\n",
    "         y_obs=fixed(tips['tip'].values),\n",
    "         alpha=fixed(alpha));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Gradient  Descent (Unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(theta0, theta1, x, y_obs):\n",
    "    y_hat = theta0 + theta1 * x\n",
    "    return np.mean((y_hat - y_obs) ** 2)\n",
    "\n",
    "def grad_mse(theta0, theta1, x, y_obs):\n",
    "    y_hat = theta0 + theta1 * x\n",
    "    n = len(x)\n",
    "    grad_0 = (-2 / n) * sum(y_obs - y_hat)\n",
    "    grad_1 = (-2 / n) * sum(x * (y_obs - y_hat)) \n",
    "    return grad_0, grad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_plot_2d_model_unscaled(epochs, loss_fn, grad_loss_fn, x, y_obs, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Uses gradient descent to minimize loss_fn. Returns the minimizing value of\n",
    "    theta once theta changes less than 0.001 between iterations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set starting epoch\n",
    "    epochs = np.arange(epochs)\n",
    "    epochs_conv = []\n",
    "    \n",
    "    # Set loss array\n",
    "    losses = []\n",
    "    losses_conv = []\n",
    "    \n",
    "    # Set theta array\n",
    "    theta0s = []\n",
    "    theta1s = []\n",
    "    \n",
    "    # Setup figure\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax2 = plt.subplot2grid((2, 2), (0, 1))\n",
    "    ax3 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax4 = plt.subplot2grid((2, 2), (1, 1), projection='3d')\n",
    "    \n",
    "    # Plot total_bill vs tip\n",
    "    sns.scatterplot(x = x, y = y_obs, ax=ax1)\n",
    "    ax1.xaxis.set_tick_params(labelsize=14)\n",
    "    ax1.yaxis.set_tick_params(labelsize=14)\n",
    "    \n",
    "    ax1.set_ylabel('Tip', fontsize=18)\n",
    "    ax1.set_xlabel('Total Bill', fontsize=18)\n",
    "    ax1.set_xlim([0, 60])\n",
    "    ax1.set_ylim([0, 12])\n",
    "    \n",
    "    # Plot 2D contour\n",
    "    theta0_grid = np.linspace(-5, 15, 200)\n",
    "    theta1_grid = np.linspace(-10, 11, 200)\n",
    "    loss_grid = np.zeros([len(theta1_grid), len(theta0_grid)])\n",
    "    for theta0_id, theta0 in enumerate(theta0_grid):\n",
    "        for theta1_id, theta1 in enumerate(theta1_grid):\n",
    "            loss_grid[theta1_id, theta0_id] = loss_fn(theta0, theta1, x, y_obs)\n",
    "    X, Y = np.meshgrid(theta0_grid, theta1_grid)\n",
    "    cp = ax3.contour(X, Y, loss_grid, 6, colors='white', linestyles='dashed', linewidths=1)\n",
    "    ax3.clabel(cp, inline=1, fmt='%1.1f', fontsize=15 )\n",
    "    ax3.contourf(X, Y, loss_grid, alpha=0.65,cmap=cm.viridis) \n",
    "    ax3.set_xlabel('$\\\\theta_0$', fontsize=18)\n",
    "    ax3.set_ylabel('$\\\\theta_1$', fontsize=18)\n",
    "\n",
    "    surf = ax4.plot_surface(X, Y, loss_grid, cmap='viridis', rstride=1, cstride=1, antialiased=True, alpha=0.65)\n",
    "    ax4.set_xlabel('$\\\\theta_0$', fontsize=18)\n",
    "    ax4.set_ylabel('$\\\\theta_1$', fontsize=18)\n",
    "    ax4.set_zlabel('Loss', fontsize=18, rotation=90)\n",
    "    \n",
    "    # Set starting theta\n",
    "    theta0 = 10.\n",
    "    theta1 = 10.\n",
    "    \n",
    "    for epoch in epochs:\n",
    "\n",
    "        # Update losses\n",
    "        losses.append(loss_fn(theta0, theta1, x, y_obs))\n",
    "        \n",
    "        # Update thetas\n",
    "        theta0s.append(theta0)\n",
    "        theta1s.append(theta1)\n",
    "        \n",
    "        # Compute gradient\n",
    "        gradient_0, gradient_1 = grad_loss_fn(theta0, theta1, x, y_obs)\n",
    "        \n",
    "        # Get new theta\n",
    "        new_theta0 = theta0 - alpha * gradient_0\n",
    "        new_theta1 = theta1 - alpha * gradient_1\n",
    "        \n",
    "        if abs(new_theta0 - theta0) < 0.001 and abs(new_theta1 - theta1) < 0.001:\n",
    "            epochs_conv.append(epoch)\n",
    "            losses_conv.append(loss_fn(theta0, theta1, x, y_obs))\n",
    "          \n",
    "        # Update theta\n",
    "        theta0 = new_theta0\n",
    "        theta1 = new_theta1\n",
    "  \n",
    "    # Check for convergence\n",
    "    ax2.plot(epochs, losses, '-o', markeredgecolor='k', ms=10)\n",
    "    ax2.set_xlim([-1, 10000])\n",
    "    ax2.set_ylim([-20, 400])\n",
    "    ax2.set_xlabel('Epoch', fontsize=18)\n",
    "    ax2.set_ylabel('Loss', fontsize=18)\n",
    "    ax2.xaxis.set_tick_params(labelsize=14)\n",
    "    ax2.yaxis.set_tick_params(labelsize=14)\n",
    "    \n",
    "    ax1.set_title('$\\\\theta_0$ = {}\\n$\\\\theta_1$ = {}'.format(np.round(theta0, 2), np.round(theta1, 2)), fontsize=18)\n",
    "    ax1.plot(x, theta0 + x*theta1, linestyle='-', lw=3, color='#fc4f30')\n",
    "    \n",
    "    ax3.plot(theta0s, theta1s, '-o', markeredgecolor='k', ms=10, zorder=10)\n",
    "    \n",
    "    ax4.plot(theta0s, theta1s, losses, '-o', markeredgecolor='k', ms=10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "\n",
    "# Launch widget\n",
    "interact(minimize_plot_2d_model_unscaled,\n",
    "         epochs=IntSlider(value=1, min=1, max=100000, step=1),\n",
    "         loss_fn=fixed(mse),\n",
    "         grad_loss_fn=fixed(grad_mse),\n",
    "         x=fixed(tips['total_bill'].values),\n",
    "         y_obs=fixed(tips['tip'].values),\n",
    "         alpha=fixed(alpha));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Gradient  Descent (Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(theta0, theta1, x, y_obs):\n",
    "    y_hat = theta0 + theta1 * x\n",
    "    return np.mean((y_hat - y_obs) ** 2)\n",
    "\n",
    "def grad_mse(theta0, theta1, x, y_obs):\n",
    "    y_hat = theta0 + theta1 * x\n",
    "    n = len(x)\n",
    "    grad_0 = (-2 / n) * sum(y_obs - y_hat)\n",
    "    grad_1 = (-2 / n) * sum(x * (y_obs - y_hat)) \n",
    "    return grad_0, grad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_plot_2d_model_scaled(epochs, loss_fn, grad_loss_fn, x, y_obs, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Uses gradient descent to minimize loss_fn. Returns the minimizing value of\n",
    "    theta once theta changes less than 0.001 between iterations.\n",
    "    \"\"\"\n",
    "    x = (x - np.mean(x)) / np.std(x)\n",
    "    y_obs = (y_obs - np.mean(y_obs)) / np.std(y_obs)\n",
    "    \n",
    "    # Set starting epoch\n",
    "    epochs = np.arange(epochs)\n",
    "    epochs_conv = []\n",
    "    \n",
    "    # Set loss array\n",
    "    losses = []\n",
    "    losses_conv = []\n",
    "    \n",
    "    # Set theta array\n",
    "    theta0s = []\n",
    "    theta1s = []\n",
    "    \n",
    "    # Setup figure\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax2 = plt.subplot2grid((2, 2), (0, 1))\n",
    "    ax3 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax4 = plt.subplot2grid((2, 2), (1, 1), projection='3d')\n",
    "    \n",
    "    # Plot total_bill vs tip\n",
    "    sns.scatterplot(x = x, y = y_obs, ax=ax1)\n",
    "    ax1.xaxis.set_tick_params(labelsize=14)\n",
    "    ax1.yaxis.set_tick_params(labelsize=14)\n",
    "    \n",
    "    ax1.set_ylabel('Tip', fontsize=18)\n",
    "    ax1.set_xlabel('Total Bill', fontsize=18)\n",
    "    ax1.set_xlim([-2, 4])\n",
    "    ax1.set_ylim([-2, 6])\n",
    "    \n",
    "    # Plot 2D contour\n",
    "    theta0_grid = np.linspace(-10, 15, 200)\n",
    "    theta1_grid = np.linspace(-10, 10, 200)\n",
    "    loss_grid = np.zeros([len(theta1_grid), len(theta0_grid)])\n",
    "    for theta0_id, theta0 in enumerate(theta0_grid):\n",
    "        for theta1_id, theta1 in enumerate(theta1_grid):\n",
    "            loss_grid[theta1_id, theta0_id] = loss_fn(theta0, theta1, x, y_obs)\n",
    "    X, Y = np.meshgrid(theta0_grid, theta1_grid)\n",
    "    cp = ax3.contour(X, Y, loss_grid, 6, colors='white', linestyles='dashed', linewidths=1)\n",
    "    ax3.clabel(cp, inline=1, fmt='%1.1f', fontsize=15 )\n",
    "    ax3.contourf(X, Y, loss_grid, alpha=0.65,cmap=cm.viridis) \n",
    "    ax3.set_xlabel('$\\\\theta_0$', fontsize=18)\n",
    "    ax3.set_ylabel('$\\\\theta_1$', fontsize=18)\n",
    "\n",
    "    surf = ax4.plot_surface(X, Y, loss_grid, cmap='viridis', rstride=1, cstride=1, antialiased=True, alpha=0.65)\n",
    "    ax4.set_xlabel('$\\\\theta_0$', fontsize=18)\n",
    "    ax4.set_ylabel('$\\\\theta_1$', fontsize=18)\n",
    "    ax4.set_zlabel('Loss', fontsize=18, rotation=90)\n",
    "    \n",
    "    # Set starting theta\n",
    "    theta0 = 12.5\n",
    "    theta1 = 7.5\n",
    "    \n",
    "    for epoch in epochs:\n",
    "\n",
    "        # Update losses\n",
    "        losses.append(loss_fn(theta0, theta1, x, y_obs))\n",
    "        \n",
    "        # Update thetas\n",
    "        theta0s.append(theta0)\n",
    "        theta1s.append(theta1)\n",
    "        \n",
    "        # Compute gradient\n",
    "        gradient_0, gradient_1 = grad_loss_fn(theta0, \n",
    "                                              theta1, \n",
    "                                              x, \n",
    "                                              y_obs)\n",
    "        \n",
    "        # Get new theta\n",
    "        new_theta0 = theta0 - alpha * gradient_0\n",
    "        new_theta1 = theta1 - alpha * gradient_1\n",
    "        \n",
    "        if abs(new_theta0 - theta0) < 0.001 and abs(new_theta1 - theta1) < 0.001:\n",
    "            epochs_conv.append(epoch)\n",
    "            losses_conv.append(loss_fn(theta0, theta1, x, y_obs))\n",
    "          \n",
    "        # Update theta\n",
    "        theta0 = new_theta0\n",
    "        theta1 = new_theta1\n",
    "  \n",
    "    # Check for convergence\n",
    "    ax2.plot(epochs, losses, '-o', markeredgecolor='k', ms=10)\n",
    "    ax2.plot(epochs_conv, losses_conv, '-o', markeredgecolor='k', ms=10)\n",
    "    ax2.set_xlim([-1, 20])\n",
    "    ax2.set_ylim([-20, 220])\n",
    "    ax2.set_xlabel('Epoch', fontsize=18)\n",
    "    ax2.set_ylabel('Loss', fontsize=18)\n",
    "    ax2.xaxis.set_tick_params(labelsize=14)\n",
    "    ax2.yaxis.set_tick_params(labelsize=14)\n",
    "    \n",
    "    ax1.set_title('$\\\\theta_0$ = {}\\n$\\\\theta_1$ = {}'.format(np.round(theta0, 2), np.round(theta1, 2)), fontsize=18)\n",
    "    ax1.plot(x, theta0 + x*theta1, linestyle='-', lw=3, color='#fc4f30')\n",
    "    if len(losses_conv) > 0:\n",
    "        ax1.vlines(x, ymin=y_obs, ymax=theta0 + x*theta1, linestyle='dashed', color='r',alpha=0.3, zorder=0)\n",
    "    \n",
    "    ax3.plot(theta0s, theta1s, '-o', markeredgecolor='k', ms=10)\n",
    "    \n",
    "    ax4.plot(theta0s, theta1s, losses, '-o', markeredgecolor='k', ms=10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "# Launch widget\n",
    "interact(minimize_plot_2d_model_scaled,\n",
    "         epochs=IntSlider(value=1, min=1, max=100, step=1),\n",
    "         loss_fn=fixed(mse),\n",
    "         grad_loss_fn=fixed(grad_mse),\n",
    "         x=fixed(tips['total_bill'].values),\n",
    "         y_obs=fixed(tips['tip'].values),\n",
    "         alpha=fixed(alpha));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
