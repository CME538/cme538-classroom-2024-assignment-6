{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CME538 - Introduction to Data Science\n",
    "## Assignment 4 - Exploratory Data Analysis\n",
    "\n",
    "**Learning Objectives**\n",
    "After completing this assignment, you should be comfortable:\n",
    "\n",
    "- Using `matplotlib` and `seaborn` for data visualization.\n",
    "- Using more advanced `Pandas` grouping and aggregating methods.\n",
    "- Resampling DateTime indices.\n",
    "- Working with datetime columns in `Pandas`.\n",
    "- Removing outliers.\n",
    "- Investigating missing data.\n",
    "\n",
    "You are free to add new cells to use as a scratch pad, but make sure to clean you code up and present your answer in the cell indicated with `# Write your code here`.\n",
    "\n",
    "**Marking Breakdown**\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "Question 1a | 1\n",
    "Question 1b | 1\n",
    "Question 1c | 1\n",
    "Question 1d | 1\n",
    "Question 1e | 1\n",
    "Question 2a | 1\n",
    "Question 2b | 1\n",
    "Question 2c | 1\n",
    "Question 3a | 1\n",
    "Question 3b | 1\n",
    "Question 4a | 1\n",
    "Question 4b | 1\n",
    "Question 4c | 1\n",
    "Question 5 | 1\n",
    "Question 6 | 1\n",
    "Question 7a | 1\n",
    "Question 7b | 1\n",
    "Question 7c | 1\n",
    "Question 7d | 1\n",
    "Question 7e | 1\n",
    "Question 7f | 1\n",
    "Question 7g | 1\n",
    "Question 8a | 1\n",
    "Question 8b | 1\n",
    "Question 8c | 1\n",
    "Question 8d | 1\n",
    "Question 8e | 1\n",
    "Total | 27\n",
    "\n",
    "One of the following marks below will be added to the **Total** above.\n",
    "\n",
    "### Code Quality\n",
    "\n",
    "| Rank | Points | Description |\n",
    "| :-- | :-- | :-- |\n",
    "| Youngling | 1 | Code is unorganized, variables names are not descriptive, redundant, memory-intensive, computationally-intensive, uncommented, error-prone, difficult to understand. |\n",
    "| Padawan | 2 | Code is organized, variables names are descriptive, satisfactory utilization of memory and computational resources, satisfactory commenting, readable. |\n",
    "| Jedi | 3 | Code is organized, easy to understand, efficient, clean, a pleasure to read. #cleancode |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import 3rd party libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure Notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"notebook\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "You've just been hired by the City of Toronto. Congratulation! Toronto has been collecting data on its bike share program since 2017 and the 2019 data has just become available. The city has implemented some new initiatives to try to increase ridership numbers such as **Free Ride Wednesdays** in the month of September and the addition of new bike lanes. You manager has asked you to:\n",
    "1. Merge the bike share data with local weather data from the TORONTO CITY CENTRE weather station.\n",
    "2. Investigate the effect of temperature on ridership numbers.   \n",
    "3. Explore different consumer behaviours between Annual Members and Casual Members.\n",
    "\n",
    "\n",
    "# 1. Prepare Weather Data\n",
    "## Question 1a\n",
    "First, let's check to see what weather files are available in the assignment directory. Weather file names have the following structure `en_climate_hourly_ON_6158355_01-2017_P1H.csv`. All weather file names contain the number `6158359`, which is the `TORONTO CITY CENTRE` weather station ID. Create a variable called `weather_filenames` and assign a list containing all weather file names to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "weather_filenames = ...\n",
    "\n",
    "# Print file names\n",
    "print(weather_filenames[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1b\n",
    "`weather_filenames` contains 12 files containing monthly weather data for 2019. Create a variable `weather_data` and assign a DataFrame to it that contains the data from all 12 `.csv` files. Hint: `pd.concat()` might be helpful.\n",
    "\n",
    "Check out this [glossary](https://climate.weather.gc.ca/glossary_e.html#windChill) to get a better understanding of what the column names refer to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "weather_data = ...\n",
    "\n",
    "# View DataFrame\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1c\n",
    "A column called `'Date/Time'` contains hourly datetime stamps in the format `YYYY-MM-DD HH:MM`. Use `pd.DatetimeIndex()` to set the `'Date/Time'` column as the index of `weather_data`. Now the index of `weather_data` is composed of `Timestamps`. Hint: 'weather_data.columns' should no longer contain `'Date/Time'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "...\n",
    "\n",
    "# View DataFrame\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1d\n",
    "The index of `weather_data` (`weather_data.index`) should be a series of Timestamps (e.g. `Timestamp('2019-01-01 00:00:00')`).\n",
    "\n",
    "Are these Timestamps localized to a time zone? If so, which one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the Timestamps are not localized, localize them to Toronto's time zone (Eastern Standard Time - `EST`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "...\n",
    "\n",
    "# View DataFrame\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1e\n",
    "Next, plot temperature as a function of the datetime index. Your plot should look something like this.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/temp_2019.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Bike Share Data\n",
    "The assignment folder contains data about bike share trips in the city of Toronto for 2019 where there is one `.csv` file for each month. File names have the structure `bike_share_YYYY-MM.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bike share file names\n",
    "trips_filenames = [filename for filename in os.listdir() if 'bike_share' in filename]\n",
    "\n",
    "# Print file names\n",
    "print(trips_filenames[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2a\n",
    "Create a variable `trips_data` and assign a DataFrame to it that contains the bike share data from all 12 `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "trips_data = ...\n",
    "\n",
    "# Let's remove double spaces from the column names\n",
    "trips_data.columns = [' '.join(col.split()) for col in trips_data.columns]              \n",
    "\n",
    "# View DataFrame\n",
    "trips_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2b\n",
    "Next, convert columns `'Start Time'` and `'End Time'` to datetimes. Then, localize `'Start Time'` and `'End Time'` to Eastern Standard Time (EST). This might take a minute or two.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "...\n",
    "\n",
    "# View DataFrame\n",
    "trips_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2c\n",
    "To check that these datetime conversions were done correctly, generate a plot of daily ride counts. Your plot should look something like this. Hint: Check out `.resample()` and consider making a new variable.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/trips_2019.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clean Bike Share Data\n",
    "## Question 3a - Missing Data\n",
    "Large datasets are rarely completely full (no missing values) and its always a good idea to evaluate if there is missing data and for what fields. \n",
    "\n",
    "First, check for missing values in `weather_data`. Create a DataFrame named `weather_data_missing` where the index in the column names of `weather_data` and there is one column named `'count'` which contains the number of missing values for a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "weather_data_missing = ...\n",
    "\n",
    "# View DataFrame\n",
    "weather_data_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, check for missing values in `trips_data`. Create a DataFrame named `trips_data_missing` where the index in the column names of `trips_data` and there is one column named `'count'` which contains the number of missing values for a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "trips_data_missing = ...\n",
    "\n",
    "# View DataFrame\n",
    "trips_data_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some columns have missing values. However, having missing data does not necessarily mean that something is wrong with an entry. For example, the `Weather` column contains the following unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['Weather'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that only non-normal/clear weather events are listed. So, when `weather_data['Weather'] == NaN`, the conditions are clear. Therefore, we would never want to remove rows where `weather_data['Weather'] == NaN`.\n",
    "\n",
    "We can see that the first 8 columns of `weather_data_missing` have no missing data, so we can leave `weather_data` and address the missingness on a case-by-case basis depending on which columns we're analyzing.\n",
    "\n",
    "For `trips_data`, we can see that `'End Station Id'` and `'End Station Name'` have 454 missing values, which is only 0.01% of the dataset. This might suggest corruption and given the small number of missing values, we can safely drop these rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3b - Missing Data\n",
    "Drop any rows of `trips_data` with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "trips_data = ...\n",
    "\n",
    "# View DataFrame\n",
    "trips_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4a - Outliers\n",
    "Outliers in your datasets can be both good and bad. One the one hand, they may contain important information while on the other hand, they skew your visualizations and may bias your models. \n",
    "\n",
    "As a simple first pass, let's look at the summary statistics for `trips_data` using `.describe()` (remember, it only works for numeric data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away we notice something a bit funny with `'Trip Duration'`. The min and max values seem implausible. A trip cannot last `0 seconds` (you'd have to be biking at the speed of light!) and its unlikely that a trip lasted for `1.240378e+07 seconds`. `1.240378e+07 seconds` is roughly 4.78 months, which would be quite the ride and cost tens of thousands of dollars. We can see that the average `'Trip Duration'` is roughly 17 minutes.\n",
    "\n",
    "We've been told by Bike Share Toronto that trips lasting less than 1 minute can be considered false trips. Remove all trips from `trips_data` with a duration less than 60 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "trips_data = ...\n",
    "\n",
    "# View DataFrame\n",
    "trips_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4b - Outliers\n",
    "Next, remove any `'Trip Duration'` values less than `Q1 - 1.5 * IQR` and greater than `Q3 + 1.5 * IQR`. \n",
    "\n",
    "- Q1: The first quartile (`.quantile(0.25)`)\n",
    "- Q3: The third quartile (`.quantile(0.75)`)\n",
    "- IQR: The first quartil (`Q3 - Q1`)\n",
    "<br>\n",
    "<img src=\"images/probability_density.png\" alt=\"drawing\" width=\"450\"/>\n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "trips_data = ...\n",
    "\n",
    "# View DataFrame\n",
    "trips_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4c - Outliers\n",
    "Plot a histogram + density plot using `sns.distplot()` of the `'Trip Duration'`. Ensure that `'Trip Duration'` is displayed in minutes. Your plot should look something like this.\n",
    "<br>\n",
    "<img src=\"images/trip_durations.png\" alt=\"drawing\" width=\"450\"/>\n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - Duplicates\n",
    "Remove any entries from `trips_data` which have the same `'Trip Id'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "trips_data = ...\n",
    "\n",
    "# View DataFrame\n",
    "trips_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Merge Datasets\n",
    "To facilitate an analysis of the effect of weather on ridership, we must merge two DataFrames (`weather_data` and `trips_data`).\n",
    "\n",
    "## Question 6\n",
    "Use the `.merge()` function to combine `weather_data` and `trips_data` using datetime information and set the output to a new variable called `data_merged`. In `trips_data` there are two time stamps corresponding to the start and end of the ride. Use the `'Start Time'` of the rides to merge. \n",
    "\n",
    "`trips_data` datetimes contain information down to the minute, while `weather_data` is reported every hour. Thus, we must merge based on a common year, month, day, hour. Hint: create a new column in `trips_data` called `'merge_time'` and set it equal to `trips_data['Start Time']` rounded to the nearest hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "data_merged = ...\n",
    "\n",
    "# View DataFrame\n",
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analysis of 'User Type'\n",
    "## Question 7a\n",
    "First, we'll explore the daily number for Annual Members and Casual Members. Casual Members pay on a per ride basis while Annual Members pay a monthly subcription fee. The DataFrame `data_merged` has a temporal resolution of a minute. Therefore, in order to look at daily numbers, we'll need to convert `data_merged` so that every row corresponds to a day. Create a new DataFrame called `data_days` with three columns:\n",
    "- ride: The total number of rides for a particular day.\n",
    "- annual_members: Number of rides by Annual Members.\n",
    "- casual_members: Number of rides by Casual Members.\n",
    "- workday: Was this day a workday (True) or a weekend day (False).\n",
    "\n",
    "Your DataFrame should looks something like this.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/data_days.png\" alt=\"drawing\" width=\"500\"/>\n",
    "<br>\n",
    "\n",
    "As a quick sanity check you can check that the number of rows in `data_merged` is equal to the sum of `data_days['rides']`.\n",
    "\n",
    "Hint: You can use the `.groupby()` method and the `agg()` method to compute this transformation in a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "data_days = ...\n",
    "\n",
    "# View DataFrame\n",
    "data_days.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7b\n",
    "Use `sns.distplot()` to create a plot showing the distributions of daily ride counts from `data_days` for Casual Members and Annual Members. Your plot should look something like this. \n",
    "\n",
    "<br>\n",
    "<img src=\"images/ride_count_histogram.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7c\n",
    "Use `sns.scatterplot()` to create a scatter plot showing the relationship between daily ride counts from `data_days` for Casual Members and Annual Members. Your plot should look something like this. \n",
    "\n",
    "<br>\n",
    "<img src=\"images/ride_count_scatter.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7d\n",
    "Looking at the figure you've generated for **Question 7c**, some interesting outliers have appeared. In particular, there are some `workday` data points that appear to follow the `non-workday` trend. What could explain these outliers and what additional information could be collected to address them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7e\n",
    "Let's examine the hourly ride counts for `Annual Members` and `Casual Members`. First thing we have to do is create a new DataFrame called `data_hours`. `data_hours` should have its index set to hours (0 to 23) using the `'Start Time'` column and three columns `'rides', 'annual_members', 'casual_members'`. These should be average hourly values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "data_hours = ...\n",
    "\n",
    "# View DataFrame\n",
    "data_hours.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7f\n",
    "Use `data_hours` to create a plot showing the average number of hourly rides for `Annual Members` and `Casual Members`. Your plot should look something like this.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/hourly_rides.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7g\n",
    "What can you observe from the plot? Hypothesize about the meaning of the peaks for casual and annual membership riders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analysis of 'Weather'\n",
    "In this section, we'll be looking at the influence of weather conditions, such as temperature and precipitation, on ridership activity.\n",
    "\n",
    "First, let's take a look at the missingness for `data_merged`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.isnull().sum(axis=0).to_frame('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `'Weather'` column has 2,141,573 missing values. Now let's take a look at the unique labels in the `'Weather'` column and how many entries contain each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.groupby('Weather')['Trip Id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most common `'Weather'` labels are `'Rain'`, `'Fog'`, and `'Rain,Fog'`. There is no label for **clear** condition, which suggests that the 2,141,573 NaN values correspond to **clear** conditions.\n",
    "\n",
    "## Question 8a\n",
    "The first thing we have to do is transform `data_merged` to contain aggregated values for each hour. Remember, `data_merged`'s granularity is at the ride level. Each row, corresponds to one ride with a temporal resolution of one minute. Therefore, there can be multiple entries for the same minute.\n",
    "\n",
    "Create a new variable called `hourly_rides_and_weather` and assign a DataFrame to it containing the following information:\n",
    "- Index: DatetimeIndex with a resolution of 1 hour (2019-01-01 10:00:00, 2019-01-01 11:00:00, 2019-01-01 12:00:00, 2019-01-01 13:00:00, etc.). Use `'Start Time'` to generate this index.\n",
    "- Column 1 `'rides'`: How many rides were recorded during a particular hour.\n",
    "- Column 2 `'annual_members'`: How many `'Annual Member'` rides were recorded during a particular hour.\n",
    "- Column 3 `'casual_members'`: How many `'Casual Member'` rides were recorded during a particular hour.\n",
    "- Column 4 `'workday'`: Does this hour correspond to a workday or a weekend day (True, False). \n",
    "- Column 5 `'temp'`: Reported temperature from the `'Temp (Â°C)'` column. \n",
    "- Column 6 `'weather'`: Reported weather conditions from the `'Weather'` column. \n",
    "\n",
    "<br>\n",
    "<img src=\"images/hourly_rides_and_weather_1.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>\n",
    "\n",
    "Hints:\n",
    "1. Use `.groupby()` and `.agg()`.\n",
    "2. This is an example of how you can use `.agg()` to compute Column 1 `'rides'`: `.agg(rides=('rides', 'sum'))`.\n",
    "3. Use `data_merged['Start Time'].dt.floor('H')` to groupby hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "hourly_rides_and_weather = ...\n",
    "\n",
    "# View DataFrame\n",
    "hourly_rides_and_weather.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8b\n",
    "Next, let's transform `hourly_rides_and_weather` from hourly to daily sampling. As we saw for **Question 7g**, there are strong trends within each day, which could complicate our initial analysis. Therefore, by aggregating by day-of-the-week, we'll remove some of this trend.\n",
    "\n",
    "Modify `hourly_rides_and_weather` to include the following information:\n",
    "- Index: DatetimeIndex with a resolution of 1 day (2019-01-01 00:00:00, 2019-01-02 00:00:00, 2019-01-03 00:00:00, 2019-01-04 00:00:00, etc.). Use `'Start Time'` to generate this index.\n",
    "- Column 1 `'rides'`: How many rides were recorded during a particular day.\n",
    "- Column 2 `'annual_members'`: How many `'Annual Member'` rides were recorded during a particular day.\n",
    "- Column 3 `'casual_members'`: How many `'Casual Member'` rides were recorded during a particular day.\n",
    "- Column 4 `'workday'`: Is this a workday or a weekend day (True, False). \n",
    "- Column 5 `'temp'`: The maximum temperature recorded for a particular day. \n",
    "- Column 6 `'weather'`: This column should contain one of two values (`'clear'` or `'Precipitation'`). `'Clear'` should be assigned to days where 50% or more of the hours of that day had no precipitation events (Rain, Fog, Snow, Rain, Fog, etc.). Remember, `hourly_rides_and_weather['weather']` contains an `NaN` value when there was no precipitation event. When more than 50% of the hours of a day had a precipitation event, assign `'Precipitation'`.  \n",
    "\n",
    "<br>\n",
    "<img src=\"images/hourly_rides_and_weather_2.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "hourly_rides_and_weather = ...\n",
    "\n",
    "# View DataFrame\n",
    "hourly_rides_and_weather.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8c\n",
    "Let's investigate the relationship between weather conditions and ridership numbers. Create a violin plot using `sns.violinplot()` that looks something like the figure below.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/weather_daily_rides_1.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8d\n",
    "Let's investigate the relationship between the maximum daily temperature and ridership numbers. Create a scatter plot using `sns.scatterplot()` that looks something like the figure below.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/temp_daily_rides.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8e\n",
    "Reflect on the figures you've generated for **Question 8c** and **Question 8d**. What trends can you identify from these plots and can you suggest any potential issues with them or modifications you'd suggest to improve them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations, you're done Assignment 4. Review your answers and clean up that code before submitting on Quercus. `#cleancode`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
